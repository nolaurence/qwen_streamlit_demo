一个在M2 Pro上运行chatglm和qwen llama3的demo

目前可以允许的模型：
[x] ChatGLM3-6B
[x] Qwen1.5-7B-Chat
[ ] Llama3

issue: Qwen 7B在mac上跑的灰常灰常慢- -不知道为啥